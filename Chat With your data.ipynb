{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb15742c-3ced-4ee7-961a-1bb195f0afa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c97176c-7c1b-473c-b944-414c12f5e5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import OpenAIWhisperParser\n",
    "from langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7ed5578-fd27-4c62-85ad-3bbfc6570d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.youtube.com/watch?v=jGwO_UgTS7I\"\n",
    "save_dir=\"docs/youtube/\"\n",
    "utube_loader = GenericLoader(YoutubeAudioLoader([url],save_dir),OpenAIWhisperParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38342e6d-5bd9-44b0-abaf-f8d12c2843ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=jGwO_UgTS7I\n",
      "[youtube] jGwO_UgTS7I: Downloading webpage\n",
      "[youtube] jGwO_UgTS7I: Downloading ios player API JSON\n",
      "[youtube] jGwO_UgTS7I: Downloading player 84314bef\n",
      "[youtube] jGwO_UgTS7I: Downloading m3u8 information\n",
      "[info] jGwO_UgTS7I: Downloading 1 format(s): 140\n",
      "[download] Destination: docs\\youtube\\Stanford CS229： Machine Learning Course, Lecture 1 - Andrew Ng (Autumn 2018).m4a\n",
      "[download] 100% of   69.76MiB in 00:00:02 at 31.09MiB/s    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: jGwO_UgTS7I: writing DASH m4a. Only some players support this container. Install ffmpeg to fix this automatically\n",
      "ERROR: Postprocessing: ffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location\n"
     ]
    },
    {
     "ename": "DownloadError",
     "evalue": "ERROR: Postprocessing: ffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPostProcessingError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3.1\\envs\\pracopenai\\lib\\site-packages\\yt_dlp\\YoutubeDL.py:3537\u001b[0m, in \u001b[0;36mYoutubeDL.process_info\u001b[1;34m(self, info_dict)\u001b[0m\n\u001b[0;32m   3536\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3537\u001b[0m     replace_info_dict(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiles_to_move\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   3538\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m PostProcessingError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3.1\\envs\\pracopenai\\lib\\site-packages\\yt_dlp\\YoutubeDL.py:3719\u001b[0m, in \u001b[0;36mYoutubeDL.post_process\u001b[1;34m(self, filename, info, files_to_move)\u001b[0m\n\u001b[0;32m   3718\u001b[0m info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__files_to_move\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m files_to_move \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m-> 3719\u001b[0m info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_all_pps\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpost_process\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madditional_pps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m__postprocessors\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3720\u001b[0m info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_pp(MoveFilesAfterDownloadPP(\u001b[38;5;28mself\u001b[39m), info)\n",
      "File \u001b[1;32m~\\anaconda3.1\\envs\\pracopenai\\lib\\site-packages\\yt_dlp\\YoutubeDL.py:3701\u001b[0m, in \u001b[0;36mYoutubeDL.run_all_pps\u001b[1;34m(self, key, info, additional_pps)\u001b[0m\n\u001b[0;32m   3700\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pp \u001b[38;5;129;01min\u001b[39;00m (additional_pps \u001b[38;5;129;01mor\u001b[39;00m []) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pps[key]:\n\u001b[1;32m-> 3701\u001b[0m     info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_pp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3702\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m info\n",
      "File \u001b[1;32m~\\anaconda3.1\\envs\\pracopenai\\lib\\site-packages\\yt_dlp\\YoutubeDL.py:3679\u001b[0m, in \u001b[0;36mYoutubeDL.run_pp\u001b[1;34m(self, pp, infodict)\u001b[0m\n\u001b[0;32m   3678\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3679\u001b[0m     files_to_delete, infodict \u001b[38;5;241m=\u001b[39m \u001b[43mpp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfodict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3680\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m PostProcessingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   3681\u001b[0m     \u001b[38;5;66;03m# Must be True and not 'only_download'\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3.1\\envs\\pracopenai\\lib\\site-packages\\yt_dlp\\postprocessor\\common.py:23\u001b[0m, in \u001b[0;36mPostProcessorMetaClass.run_wrapper.<locals>.run\u001b[1;34m(self, info, *args, **kwargs)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_progress({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstarted\u001b[39m\u001b[38;5;124m'\u001b[39m}, info_copy)\n\u001b[1;32m---> 23\u001b[0m ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, info, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3.1\\envs\\pracopenai\\lib\\site-packages\\yt_dlp\\postprocessor\\common.py:128\u001b[0m, in \u001b[0;36mPostProcessor._restrict_to.<locals>.decorator.<locals>.wrapper\u001b[1;34m(self, info)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allowed[format_type]:\n\u001b[1;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3.1\\envs\\pracopenai\\lib\\site-packages\\yt_dlp\\postprocessor\\ffmpeg.py:493\u001b[0m, in \u001b[0;36mFFmpegExtractAudioPP.run\u001b[1;34m(self, information)\u001b[0m\n\u001b[0;32m    491\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [], information\n\u001b[1;32m--> 493\u001b[0m filecodec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_audio_codec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filecodec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3.1\\envs\\pracopenai\\lib\\site-packages\\yt_dlp\\postprocessor\\ffmpeg.py:241\u001b[0m, in \u001b[0;36mFFmpegPostProcessor.get_audio_codec\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobe_available \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavailable:\n\u001b[1;32m--> 241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PostProcessingError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mPostProcessingError\u001b[0m: ffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mDownloadError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mutube_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3.1\\envs\\pracopenai\\lib\\site-packages\\langchain_core\\document_loaders\\base.py:29\u001b[0m, in \u001b[0;36mBaseLoader.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[0;32m     28\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load data into Document objects.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3.1\\envs\\pracopenai\\lib\\site-packages\\langchain_community\\document_loaders\\generic.py:115\u001b[0m, in \u001b[0;36mGenericLoader.lazy_load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlazy_load\u001b[39m(\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    113\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Document]:\n\u001b[0;32m    114\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load documents lazily. Use this when working at a large scale.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m blob \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblob_loader\u001b[38;5;241m.\u001b[39myield_blobs():  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    116\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblob_parser\u001b[38;5;241m.\u001b[39mlazy_parse(blob)\n",
      "File \u001b[1;32m~\\anaconda3.1\\envs\\pracopenai\\lib\\site-packages\\langchain_community\\document_loaders\\blob_loaders\\youtube_audio.py:45\u001b[0m, in \u001b[0;36mYoutubeAudioLoader.yield_blobs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murls:\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m# Download file\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m yt_dlp\u001b[38;5;241m.\u001b[39mYoutubeDL(ydl_opts) \u001b[38;5;28;01mas\u001b[39;00m ydl:\n\u001b[1;32m---> 45\u001b[0m         \u001b[43mydl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Yield the written blobs\u001b[39;00m\n\u001b[0;32m     48\u001b[0m loader \u001b[38;5;241m=\u001b[39m FileSystemBlobLoader(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir, glob\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.m4a\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3.1\\envs\\pracopenai\\lib\\site-packages\\yt_dlp\\YoutubeDL.py:3583\u001b[0m, in \u001b[0;36mYoutubeDL.download\u001b[1;34m(self, url_list)\u001b[0m\n\u001b[0;32m   3580\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SameFileError(outtmpl)\n\u001b[0;32m   3582\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m url_list:\n\u001b[1;32m-> 3583\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__download_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_info\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3584\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_generic_extractor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforce_generic_extractor\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download_retcode\n",
      "File \u001b[1;32m~\\anaconda3.1\\envs\\pracopenai\\lib\\site-packages\\yt_dlp\\YoutubeDL.py:3558\u001b[0m, in \u001b[0;36mYoutubeDL.__download_wrapper.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   3555\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m   3556\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   3557\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3558\u001b[0m         res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3559\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m UnavailableVideoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   3560\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreport_error(e)\n",
      "File \u001b[1;32m~\\anaconda3.1\\envs\\pracopenai\\lib\\site-packages\\yt_dlp\\YoutubeDL.py:1595\u001b[0m, in \u001b[0;36mYoutubeDL.extract_info\u001b[1;34m(self, url, download, ie_key, extra_info, process, force_generic_extractor)\u001b[0m\n\u001b[0;32m   1593\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m ExistingVideoReached()\n\u001b[0;32m   1594\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1595\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__extract_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_info_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1596\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1597\u001b[0m     extractors_restricted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallowed_extractors\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3.1\\envs\\pracopenai\\lib\\site-packages\\yt_dlp\\YoutubeDL.py:1606\u001b[0m, in \u001b[0;36mYoutubeDL._handle_extraction_exceptions.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1604\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m   1605\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1606\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1607\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (DownloadCancelled, LazyList\u001b[38;5;241m.\u001b[39mIndexError, PagedList\u001b[38;5;241m.\u001b[39mIndexError):\n\u001b[0;32m   1608\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3.1\\envs\\pracopenai\\lib\\site-packages\\yt_dlp\\YoutubeDL.py:1762\u001b[0m, in \u001b[0;36mYoutubeDL.__extract_info\u001b[1;34m(self, url, ie, download, extra_info, process)\u001b[0m\n\u001b[0;32m   1760\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m process:\n\u001b[0;32m   1761\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_video(ie_result)\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_ie_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mie_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ie_result\n",
      "File \u001b[1;32m~\\anaconda3.1\\envs\\pracopenai\\lib\\site-packages\\yt_dlp\\YoutubeDL.py:1821\u001b[0m, in \u001b[0;36mYoutubeDL.process_ie_result\u001b[1;34m(self, ie_result, download, extra_info)\u001b[0m\n\u001b[0;32m   1819\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m   1820\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_extra_info(ie_result, extra_info)\n\u001b[1;32m-> 1821\u001b[0m     ie_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_video_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mie_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1822\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_pending_errors(ie_result)\n\u001b[0;32m   1823\u001b[0m     additional_urls \u001b[38;5;241m=\u001b[39m (ie_result \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madditional_urls\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3.1\\envs\\pracopenai\\lib\\site-packages\\yt_dlp\\YoutubeDL.py:2993\u001b[0m, in \u001b[0;36mYoutubeDL.process_video_result\u001b[1;34m(self, info_dict, download)\u001b[0m\n\u001b[0;32m   2991\u001b[0m downloaded_formats\u001b[38;5;241m.\u001b[39mappend(new_info)\n\u001b[0;32m   2992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2993\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2994\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MaxDownloadsReached:\n\u001b[0;32m   2995\u001b[0m     max_downloads_reached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3.1\\envs\\pracopenai\\lib\\site-packages\\yt_dlp\\YoutubeDL.py:3539\u001b[0m, in \u001b[0;36mYoutubeDL.process_info\u001b[1;34m(self, info_dict)\u001b[0m\n\u001b[0;32m   3537\u001b[0m     replace_info_dict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_process(dl_filename, info_dict, files_to_move))\n\u001b[0;32m   3538\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m PostProcessingError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3539\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreport_error\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPostprocessing: \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   3541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3.1\\envs\\pracopenai\\lib\\site-packages\\yt_dlp\\YoutubeDL.py:1073\u001b[0m, in \u001b[0;36mYoutubeDL.report_error\u001b[1;34m(self, message, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1068\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreport_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, message, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1069\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m   1070\u001b[0m \u001b[38;5;124;03m    Do the same as trouble, but prefixes the message with 'ERROR:', colored\u001b[39;00m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;124;03m    in red if stderr is a tty file.\u001b[39;00m\n\u001b[0;32m   1072\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m-> 1073\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrouble(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_err(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mERROR:\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mStyles\u001b[38;5;241m.\u001b[39mERROR)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3.1\\envs\\pracopenai\\lib\\site-packages\\yt_dlp\\YoutubeDL.py:1012\u001b[0m, in \u001b[0;36mYoutubeDL.trouble\u001b[1;34m(self, message, tb, is_error)\u001b[0m\n\u001b[0;32m   1010\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1011\u001b[0m         exc_info \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n\u001b[1;32m-> 1012\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DownloadError(message, exc_info)\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download_retcode \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mDownloadError\u001b[0m: ERROR: Postprocessing: ffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location"
     ]
    }
   ],
   "source": [
    "utube_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8163acfe-22f7-4096-8223-c8c9e42bb232",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "649c11ed-ec98-469e-b859-8c9ac05fc559",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\"https://stackoverflow.co/teams/ai/?utm_medium=referral&utm_source=stackoverflow-community&utm_campaign=top-nav-bar&utm_content=overflowai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e23da7f8-3b45-4f50-baad-76f6164c7da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa4b4bfb-b06b-4658-b779-c23b49797f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of pages from the document is 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nEmpower your organization for an AI future with Stack Overflow for Teams - Stack Overflow\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nProductsMenu Why Teams? Our solutionIntegrationsFeaturesCustomer SuccessSecurityReturn on Investment (ROI) Use cases  Engineers  Data Scientists  DevOps & SREs  Support  Product Management  Customers  Resources Learning centerCustomer help centerFrequently Asked Questions OverflowAI  Pricing  Log in  Try free  Contact us Stack Overflow for Teams Where developers and technologists share private knowledge with coworkers.Stack Overflow Advertising Where companies reach the world’s largest audience of developers and technologists.Join the community Where developers and technologists go to gain and share knowledge. GenAI features for Teams and our public platform  Train and fine-tune large language models Blog Writing on software and technology along with company news and product updates.Labs Keep up-to-date and explore the future of collective knowledge sharing. AI features to supercharge your workflows.  Talk to an expert Enhanced SearchSummarize multiple answers across your knowledge base into new insights.Stack Overflow for\\xa0Visual Studio CodeThe power of Stack Overflow in your coding environment.Auto-Answer AppAutomate access to essential team knowledge. Free Basic Business Enterprise Learn more about pricing and plans We’re bringing AI power to your knowledge community.  Enhanced Search Stack Overflow for\\xa0Visual Studio Code Auto-Answer App Talk to an expert  Enhanced SearchUpgrade your search experience.Summarize multiple answers across your knowledge base into new insights. Play overview video Source and summarize knowledge to move past blockers faster.Get summarized insights from the global Stack Overflow community. Stack Overflow for\\xa0Visual Studio CodeTake your developer experience to the next level.The power of Stack Overflow in your coding environment. Play overview video Better understand how your code works with code explanations.Share your discoveries back to your team without breaking your flow. Auto-Answer AppAutomate access to essential team knowledge.Spend less time and resources providing and searching for answers. Play overview video Source information automatically without needing Slack commands.Return answers automatically to select Microsoft Teams channels. Level up your Enterprise plan. OverflowAI is a GenAI-powered add-on for Stack Overflow for Teams Enterprise. Enterprise  Custom pricing  Let’s talk about what you need  Talk to an expert Premium features of Business plus…Unlimited Teams within your instanceCommunites on TeamsRobust read and write APIYour own customer success and community building representative99.5% uptime SLA and priority supportContent HealthUnlimited teammates +$10 additional costper user/per month  Enhanced Search Stack Overflow for\\xa0Visual Studio Code Auto-Answer App More features coming soon… Your top questions answeredFrequently asked questions.We already use GitHub Copilot. How is this different?AI-powered code generation tools like GitHub Copilot make it easier to write boilerplate code, but they don’t eliminate the need to consult with your organization’s domain experts to work through logic, debugging, and other complex problems.Stack Overflow for Teams is a knowledge-sharing platform that transfers contextual knowledge validated by your domain experts to other employees, and can even be used to foster a code generation community of practice that champions early adopters and scales their learnings. OverflowAI makes this trusted internal knowledge—along with knowledge validated by the global Stack Overflow community—instantly accessible in places like your IDE so it can be used alongside code generation tools to learn more about your codebase and speed up your time-to-production.We already have too many tools. Why do we need this?Sometimes the number of tools isn’t the problem—low tool adoption is. Low tool adoption often occurs because people don’t know where to find help or who to ask about issues, processes, and best practices.This is where Stack Overflow for Teams shines—it drives tool adoption by scaling communities of practice and domain expertise. Many organizations use it to optimize their developer experience, and OverflowAI takes it to the next level with validated answers that span your internal community, stackoverflow.com, and soon, tools like GitHub and Jira. To prevent tool switching, we offer a robust read/write API and out-of-the-box integrations. And to help drive long-term engagement, we offer tailored knowledge management services and actionable analytics.We already use ChatGPT. How is this different?ChatGPT is designed to generate answers for individuals, using existing resources. People can save their prompt history, but others in the organization can’t discover or search their history. That leaves people operating in silos, potentially duplicating efforts or expanding knowledge gaps. ChatGPT also doesn’t maintain and update knowledge.Stack Overflow for Teams is built with a knowledge-sharing community as the foundation. It removes silos by collecting and distributing trusted knowledge throughout your organization, and can even be used alongside ChatGPT to foster a community of practice. Features like Content Health and Communities encourage teams to document, validate, and maintain knowledge in a central place. OverflowAI then summarizes this knowledge—along with knowledge validated by the global Stack Overflow community—into attributed insights in your web browser, IDE, and chat apps.How is this different from Enterprise Search tools?Enterprise Search tools are great for surfacing existing knowledge, but they aren’t great for documenting or managing new knowledge.Stack Overflow for Teams provides a fresh source of contextual knowledge that’s shared, validated, and maintained by your internal community. It offers features like gamification, Communities, and Content Health that Enterprise Search tools typically don’t have, and has a robust read/write API so you can surface Stack Overflow for Teams knowledge in your own portals and search tools. Enhanced Search upgrades your search experience by summarizing the most relevant search results across private and public Stack Overflow knowledge into answers that attribute sources.This looks like just another thing I would need to manage.Good news: We do a lot of the management for you!Stack Overflow for Teams and OverflowAI are hosted by us so you’ll always be on the latest version and have uninterrupted access to new features. You’ll also receive white-glove support with our tailored knowledge management services, which include onboarding and training, communication best practices and templates, rollout planning, and more. We’ve even been awarded “Most Implementable” by G2. And much of the platform has been designed to programmatically promote engagement with features like smart recommendations and gamification.Build a world-class developer experience with OverflowAI and Stack Overflow for Teams.Talk to an expertG2 review site logoNamed in two of G2’s lists of Best Software for 2024! 4.5/5 LightDarkAuto Stack Overflow for Teams PricingCustomersOur solutionIntegrationsFeaturesCustomer SuccessSecurityReturn on Investment (ROI)OverflowAI NEWNow available on Enterprise.Try freeLog inUse casesEngineersData ScientistsDevOps & SRESupportProduct ManagmentResourcesProductivityAI/MLGuides and InsightsCustomer AcademyFAQHelp center Stack Overflow Advertising Why Stack Overflow?What to expectAdvertise to developersAttract tech talentEngage your communityPost a job Powered by IndeedUse casesMarketing TeamsEmployer Branding TeamsDevRel TeamsTalent TeamsTechnology TeamsAgenciesResourcesProduct guides & insightsCommunity insightsAdvertising best practicesTalent best practicesCollectives™ Company  OverflowAPI NEW Stack Overflow’s subscription-based API service to train and fine-tune large language models. AboutLeadershipSocial ImpactPressCareersOpen positionsContact usBlogNewsletterPodcastLabs Site design / logo © 2024 Stack Exchange Inc. User contributions licensed under\\xa0CC BY-SA. TermsPrivacy policyCookie policyCookie settings Go to stackoverflow.com \\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'The number of pages from the document is {len(documents)}')\n",
    "documents[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42a9f91d-8304-4f38-8be1-1003d5d1bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter, TokenTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ee285a6-1cb2-4014-bd3c-be9cfa6f8656",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = 'abcdefghijklmnopqrstuvwxyzabcdefg'\n",
    "char_text_splitter = CharacterTextSplitter(chunk_size = 15, chunk_overlap = 4, separator = '')\n",
    "re_char_text_splitter = RecursiveCharacterTextSplitter(chunk_size = 150, chunk_overlap = 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3f20959-9082-47f5-9798-036dcd0fb825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmno', 'lmnopqrstuvwxyz', 'wxyzabcdefg']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_text_splitter.split_text(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0044fb7-58a4-4f78-a047-ef120d00aa95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyzabcdefg']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_char_text_splitter.split_text(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e48ea543-f147-4908-8c26-006fc56d0a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopq', 'opqrstuvwxyz', 'xyzabcdefg']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_splitter = TokenTextSplitter(chunk_size=8, chunk_overlap=2)\n",
    "token_splitter.split_text(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a08e17e2-298b-4b09-8d85-dd3a2a621a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each splitter has two functions split_text and split_document \n",
    "# the split_text function is used to split a str object into multiple strings\n",
    "# the split_document function is used to split documents loaded by the document loader\n",
    "# once the split_document function splits the document pages further, it sustains the metadata across all documents\n",
    "# any splitter has few characterstics that define it: the chunk size\n",
    "# the splitting logic, the chunk overlap and the logic to find the length of a split data: this length is used to determine the size of any chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc438a7f-cd65-4328-be9d-70949ea3d946",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_pages = re_char_text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd4cffeb-3b3a-4604-880e-1124a78fc34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The documents have been split into 57\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(page_content='Empower your organization for an AI future with Stack Overflow for Teams - Stack Overflow', metadata={'source': 'https://stackoverflow.co/teams/ai/?utm_medium=referral&utm_source=stackoverflow-community&utm_campaign=top-nav-bar&utm_content=overflowai', 'title': 'Empower your organization for an AI future with Stack Overflow for Teams - Stack Overflow', 'description': 'Build a collective, enterprise-grade knowledge base around technology transformations, including GenAI and AI/ML.', 'language': 'en'})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'The documents have been split into {len(split_pages)}')\n",
    "split_pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bee8abf-9a7b-4707-9374-718b7296f061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of documents loaded from cs229 are 216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(page_content='CS229 Lecture Notes\\nAndrew Ng\\nUpdated by Tengyu Ma', metadata={'source': 'https://cs229.stanford.edu/lectures-spring2022/main_notes.pdf', 'page': 0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "cs229_loader = PyPDFLoader('https://cs229.stanford.edu/lectures-spring2022/main_notes.pdf')\n",
    "cs229_docs = cs229_loader.load()\n",
    "print(f'The number of documents loaded from cs229 are {len(cs229_docs)}')\n",
    "cs229_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50c39e91-bb9b-4b50-8cf6-eb140ff26a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CS229 documents have been split into 352 pages\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(page_content='CS229 Lecture Notes\\nAndrew Ng\\nUpdated by Tengyu Ma', metadata={'source': 'https://cs229.stanford.edu/lectures-spring2022/main_notes.pdf', 'page': 0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_char_splitter = RecursiveCharacterTextSplitter(chunk_size = 1500, chunk_overlap = 150)\n",
    "split_pages = rec_char_splitter.split_documents(cs229_docs)\n",
    "print(f'The CS229 documents have been split into {len(split_pages)} pages')\n",
    "split_pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c21a4a3f-28db-41e8-950d-48dbdb67dcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "embedding = OpenAIEmbeddings(api_key = api_key)\n",
    "save_directory = '/chroma/persist1/'\n",
    "vectordb = Chroma.from_documents(documents = split_pages, embedding= embedding,persist_directory=save_directory)\n",
    "# we can persist the embeddings extracted within the memory with Chroma, instead of connecting to a external database server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba71f880-637f-42de-b8e5-cc35c41188ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "704"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb._collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6a80616-4661-43c5-9021-2a9bf61bc210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='CS229 Lecture Notes\\nAndrew Ng\\nUpdated by Tengyu Ma', metadata={'page': 0, 'source': 'https://cs229.stanford.edu/lectures-spring2022/main_notes.pdf'}),\n",
       "  0.27768057584762573),\n",
       " (Document(page_content='CS229 Lecture Notes\\nAndrew Ng\\nUpdated by Tengyu Ma', metadata={'page': 0, 'source': 'https://cs229.stanford.edu/lectures-spring2022/main_notes.pdf'}),\n",
       "  0.27768057584762573)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'Who are the authors of CS229 lecture notes?'\n",
    "vectordb.similarity_search_with_score(query,k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a45c561b-9ce6-4101-895a-61c17cb2c859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='Contents\\nI Supervised learning 5\\n1 Linear regression 8\\n1.1 LMS algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . 9\\n1.2 The normal equations . . . . . . . . . . . . . . . . . . . . . . . 13\\n1.2.1 Matrix derivatives . . . . . . . . . . . . . . . . . . . . . 13\\n1.2.2 Least squares revisited . . . . . . . . . . . . . . . . . . 14\\n1.3 Probabilistic interpretation . . . . . . . . . . . . . . . . . . . . 15\\n1.4 Locally weighted linear regression (optional reading) . . . . . . 17\\n2 Classiﬁcation and logistic regression 20\\n2.1 Logistic regression . . . . . . . . . . . . . . . . . . . . . . . . 20\\n2.2 Digression: the perceptron learning algorithn . . . . . . . . . . 23\\n2.3 Another algorithm for maximizing ℓ(θ) . . . . . . . . . . . . . 24\\n3 Generalized linear models 26\\n3.1 The exponential family . . . . . . . . . . . . . . . . . . . . . . 26\\n3.2 Constructing GLMs . . . . . . . . . . . . . . . . . . . . . . . . 28\\n3.2.1 Ordinary least squares . . . . . . . . . . . . . . . . . . 29\\n3.2.2 Logistic regression . . . . . . . . . . . . . . . . . . . . 30\\n3.2.3 Softmax regression . . . . . . . . . . . . . . . . . . . . 30\\n4 Generative learning algorithms 35\\n4.1 Gaussian discriminant analysis . . . . . . . . . . . . . . . . . . 36\\n4.1.1 The multivariate normal distribution . . . . . . . . . . 36\\n4.1.2 The Gaussian discriminant analysis model . . . . . . . 39\\n4.1.3 Discussion: GDA and logistic regression . . . . . . . . 41', metadata={'page': 1, 'source': 'https://cs229.stanford.edu/lectures-spring2022/main_notes.pdf'}),\n",
       "  0.3779659867286682),\n",
       " (Document(page_content='Contents\\nI Supervised learning 5\\n1 Linear regression 8\\n1.1 LMS algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . 9\\n1.2 The normal equations . . . . . . . . . . . . . . . . . . . . . . . 13\\n1.2.1 Matrix derivatives . . . . . . . . . . . . . . . . . . . . . 13\\n1.2.2 Least squares revisited . . . . . . . . . . . . . . . . . . 14\\n1.3 Probabilistic interpretation . . . . . . . . . . . . . . . . . . . . 15\\n1.4 Locally weighted linear regression (optional reading) . . . . . . 17\\n2 Classiﬁcation and logistic regression 20\\n2.1 Logistic regression . . . . . . . . . . . . . . . . . . . . . . . . 20\\n2.2 Digression: the perceptron learning algorithn . . . . . . . . . . 23\\n2.3 Another algorithm for maximizing ℓ(θ) . . . . . . . . . . . . . 24\\n3 Generalized linear models 26\\n3.1 The exponential family . . . . . . . . . . . . . . . . . . . . . . 26\\n3.2 Constructing GLMs . . . . . . . . . . . . . . . . . . . . . . . . 28\\n3.2.1 Ordinary least squares . . . . . . . . . . . . . . . . . . 29\\n3.2.2 Logistic regression . . . . . . . . . . . . . . . . . . . . 30\\n3.2.3 Softmax regression . . . . . . . . . . . . . . . . . . . . 30\\n4 Generative learning algorithms 35\\n4.1 Gaussian discriminant analysis . . . . . . . . . . . . . . . . . . 36\\n4.1.1 The multivariate normal distribution . . . . . . . . . . 36\\n4.1.2 The Gaussian discriminant analysis model . . . . . . . 39\\n4.1.3 Discussion: GDA and logistic regression . . . . . . . . 41', metadata={'page': 1, 'source': 'https://cs229.stanford.edu/lectures-spring2022/main_notes.pdf'}),\n",
       "  0.3779659867286682),\n",
       " (Document(page_content='Chapter 1\\nLinear regression\\nTo make our housing example more interesting, let’s consider a slightly richer\\ndataset in which we also know the number of bedrooms in each house:\\nLiving area (feet2)#bedrooms Price (1000 $s)\\n2104 3 400\\n1600 3 330\\n2400 3 369\\n1416 2 232\\n3000 4 540\\n.........\\nHere, thex’s are two-dimensional vectors in R2. For instance, x(i)\\n1is the\\nliving area of the i-th house in the training set, and x(i)\\n2is its number of\\nbedrooms. (In general, when designing a learning problem, it will be up to\\nyou to decide what features to choose, so if you are out in Portland gathering\\nhousing data, you might also decide to include other features such as whether\\neach house has a ﬁreplace, the number of bathrooms, and so on. We’ll say\\nmore about feature selection later, but for now let’s take the features as\\ngiven.)\\nTo perform supervised learning, we must decide how we’re going to rep-\\nresent functions/hypotheses hin a computer. As an initial choice, let’s say\\nwe decide to approximate yas a linear function of x:\\nhθ(x) =θ0+θ1x1+θ2x2\\nHere, theθi’s are the parameters (also called weights ) parameterizing the\\nspace of linear functions mapping from XtoY. When there is no risk of\\n8', metadata={'page': 8, 'source': 'https://cs229.stanford.edu/lectures-spring2022/main_notes.pdf'}),\n",
       "  0.38384220004081726)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'What does the lecture notes say about regression in page 20'\n",
    "vectordb.similarity_search_with_score(query,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0310830b-e912-4b27-8a44-54d964d05889",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "import lark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4dc2ad2-92b3-4a9b-aaef-5fac4cccbc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"The source of the page within the lecture notes. It should always be `https://cs229.stanford.edu/lectures-spring2022/main_notes.pdf`\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"page\",\n",
    "        description=\"The page from the lecture\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1eb177f4-a7e5-4e32-9d64-0d3efd94acef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\anaconda3.1\\envs\\pracopenai\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(model='gpt-3.5-turbo-instruct', temperature=0, api_key = api_key)\n",
    "document_content_description = \"Lecture notes\"\n",
    "retriever = SelfQueryRetriever.from_llm(llm, vectordb, document_content_description, metadata_field_info, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ddddf49-4e58-42d1-bd2f-4079c726f946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "self_query_retrieved_docs = retriever.invoke(query)\n",
    "print(len(self_query_retrieved_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b4e346a-ba75-4a0b-84b0-f0a6c19e0d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document is retrieved from the page: {'page': 20, 'source': 'https://cs229.stanford.edu/lectures-spring2022/main_notes.pdf'}\n",
      "The document is retrieved from the page: {'page': 20, 'source': 'https://cs229.stanford.edu/lectures-spring2022/main_notes.pdf'}\n"
     ]
    }
   ],
   "source": [
    "self_query_retrieved_docs\n",
    "for doc in self_query_retrieved_docs:\n",
    "    print(f'The document is retrieved from the page: {doc.metadata}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "33defa15-5c36-4c1c-b536-419293f598d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e5286530-0f5d-4c54-a921-cc4d3e39f86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "compressed_retriver = ContextualCompressionRetriever(base_compressor = compressor, base_retriever = vectordb.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "82811852-402c-4fe7-85a8-5eec2b05ddac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Chapter 1\\nLinear regression\\nTo make our housing example more interesting, let’s consider a slightly richer\\ndataset in which we also know the number of bedrooms in each house:\\nLiving area (feet2)#bedrooms Price (1000 $s)\\n2104 3 400\\n1600 3 330\\n2400 3 369\\n1416 2 232\\n3000 4 540\\n.........\\nHere, thex’s are two-dimensional vectors in R2. For instance, x(i)\\n1is the\\nliving area of the i-th house in the training set, and x(i)\\n2is its number of\\nbedrooms. (In general, when designing a learning problem, it will be up to\\nyou to decide what features to choose, so if you are out in Portland gathering\\nhousing data, you might also decide to include other features such as whether\\neach house has a ﬁreplace, the number of bathrooms, and so on. We’ll say\\nmore about feature selection later, but for now let’s take the features as\\ngiven.)\\nTo perform supervised learning, we must decide how we’re going to rep-\\nresent functions/hypotheses hin a computer. As an initial choice, let’s say\\nwe decide to approximate yas a linear function of x:\\nhθ(x) =θ0+θ1x1+θ2x2\\nHere, theθi’s are the parameters (also called weights ) parameterizing the\\nspace of linear functions mapping from XtoY. When there is no risk of\\n8', metadata={'page': 8, 'source': 'https://cs229.stanford.edu/lectures-spring2022/main_notes.pdf'}),\n",
       " Document(page_content='Chapter 1\\nLinear regression\\nTo make our housing example more interesting, let’s consider a slightly richer\\ndataset in which we also know the number of bedrooms in each house:\\nLiving area (feet2)#bedrooms Price (1000 $s)\\n2104 3 400\\n1600 3 330\\n2400 3 369\\n1416 2 232\\n3000 4 540\\n.........\\nHere, thex’s are two-dimensional vectors in R2. For instance, x(i)\\n1is the\\nliving area of the i-th house in the training set, and x(i)\\n2is its number of\\nbedrooms. (In general, when designing a learning problem, it will be up to\\nyou to decide what features to choose, so if you are out in Portland gathering\\nhousing data, you might also decide to include other features such as whether\\neach house has a ﬁreplace, the number of bathrooms, and so on. We’ll say\\nmore about feature selection later, but for now let’s take the features as\\ngiven.)\\nTo perform supervised learning, we must decide how we’re going to rep-\\nresent functions/hypotheses hin a computer. As an initial choice, let’s say\\nwe decide to approximate yas a linear function of x:\\nhθ(x) =θ0+θ1x1+θ2x2\\nHere, theθi’s are the parameters (also called weights ) parameterizing the\\nspace of linear functions mapping from XtoY. When there is no risk of\\n8', metadata={'page': 8, 'source': 'https://cs229.stanford.edu/lectures-spring2022/main_notes.pdf'}),\n",
       " Document(page_content='1.4 Locally weighted linear regression (optional\\nreading)\\nConsider the problem of predicting yfromx∈R. The leftmost ﬁgure below\\nshows the result of ﬁtting a y=θ0+θ1xto a dataset. We see that the data\\ndoesn’t really lie on straight line, and so the ﬁt is not very good.', metadata={'page': 17, 'source': 'https://cs229.stanford.edu/lectures-spring2022/main_notes.pdf'}),\n",
       " Document(page_content='1.4 Locally weighted linear regression (optional\\nreading)\\nConsider the problem of predicting yfromx∈R. The leftmost ﬁgure below\\nshows the result of ﬁtting a y=θ0+θ1xto a dataset. We see that the data\\ndoesn’t really lie on straight line, and so the ﬁt is not very good.', metadata={'page': 17, 'source': 'https://cs229.stanford.edu/lectures-spring2022/main_notes.pdf'})]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'What is regression?'\n",
    "vectordb.as_retriever().invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "881bc12d-035d-460a-a512-a05551b49489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='- To perform supervised learning, we must decide how we’re going to rep-\\nresent functions/hypotheses hin a computer. As an initial choice, let’s say\\nwe decide to approximate yas a linear function of x:\\nhθ(x) =θ0+θ1x1+θ2x2\\nHere, theθi’s are the parameters (also called weights ) parameterizing the\\nspace of linear functions mapping from XtoY.', metadata={'page': 8, 'source': 'https://cs229.stanford.edu/lectures-spring2022/main_notes.pdf'}),\n",
       " Document(page_content='- To perform supervised learning, we must decide how we’re going to rep-\\nresent functions/hypotheses hin a computer. As an initial choice, let’s say\\nwe decide to approximate yas a linear function of x:\\nhθ(x) =θ0+θ1x1+θ2x2\\nHere, theθi’s are the parameters (also called weights ) parameterizing the\\nspace of linear functions mapping from XtoY.', metadata={'page': 8, 'source': 'https://cs229.stanford.edu/lectures-spring2022/main_notes.pdf'})]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_retriver.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "adc8f7dc-e5af-457c-a869-5f087c78f543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='- To perform supervised learning, we must decide how we’re going to rep-\\nresent functions/hypotheses hin a computer. As an initial choice, let’s say\\nwe decide to approximate yas a linear function of x:\\nhθ(x) =θ0+θ1x1+θ2x2\\nHere, theθi’s are the parameters (also called weights ) parameterizing the\\nspace of linear functions mapping from XtoY.', metadata={'page': 8, 'source': 'https://cs229.stanford.edu/lectures-spring2022/main_notes.pdf'}),\n",
       " Document(page_content='- \"This chapter discusses tools to analyze and understand the generalization of machine learning models\"\\n- \"Recall that for supervised learning problems, given a training dataset{(x(i),y(i))}n i=1, we typically learn a model hθby minimizing a loss/cost function J(θ)\"\\n- \"The most important evaluation metric of a model is the loss on unseen test examples\"\\n- \"Formally, we sample a test example ( x,y) from the so-called test distribution D, and measure the model’s error on it, by, e.g., the mean squared error, ( hθ(x)−y)2\"\\n- \"The expected loss/error over the randomness of the test example is called the test loss/error,1 L(θ) =E(x,y)∼D[(y−hθ(x))2]\"', metadata={'page': 103, 'source': 'https://cs229.stanford.edu/lectures-spring2022/main_notes.pdf'}),\n",
       " Document(page_content='Regularization is an important technique in machine learning that involves adding an additional term, called a regularizer, to the training loss/cost function. The regularizer is typically chosen to be some measure of the complexity of the model.', metadata={'page': 125, 'source': 'https://cs229.stanford.edu/lectures-spring2022/main_notes.pdf'}),\n",
       " Document(page_content='- \"informally we can think of our prediction as being very conﬁdent that y= 1 ifθTx≫0.\"\\n- \"Similarly, we think of logistic regression as conﬁdently predictingy= 0, ifθTx≪0.\"\\n- \"Given a training set, again informally it seems that we’d have found a good ﬁt to the training data if we can ﬁnd θso that θTx(i)≫0 whenever y(i)= 1, andθTx(i)≪0 whenever y(i)= 0.\"', metadata={'page': 60, 'source': 'https://cs229.stanford.edu/lectures-spring2022/main_notes.pdf'})]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_retriever_mmr = ContextualCompressionRetriever(base_compressor = compressor, base_retriever = vectordb.as_retriever(search_type='mmr'))\n",
    "compressed_retriever_mmr.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cd3c2eed-1118-41c9-a03f-299b1d3141f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import SVMRetriever\n",
    "from langchain.retrievers import TFIDFRetriever\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "693cd1b9-f1be-40b6-a93b-d30b8ea38bd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svm_retriever = SVMRetriever.from_documents(split_pages,embedding)\n",
    "tfidf_retriever = TFIDFRetriever.from_documents(split_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ee3bbb4f-4c40-4c95-8050-7645261df904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Part III\\nGeneralization and\\nregularization\\n102', metadata={'source': 'https://cs229.stanford.edu/lectures-spring2022/main_notes.pdf', 'page': 102}),\n",
       " Document(page_content='Chapter 1\\nLinear regression\\nTo make our housing example more interesting, let’s consider a slightly richer\\ndataset in which we also know the number of bedrooms in each house:\\nLiving area (feet2)#bedrooms Price (1000 $s)\\n2104 3 400\\n1600 3 330\\n2400 3 369\\n1416 2 232\\n3000 4 540\\n.........\\nHere, thex’s are two-dimensional vectors in R2. For instance, x(i)\\n1is the\\nliving area of the i-th house in the training set, and x(i)\\n2is its number of\\nbedrooms. (In general, when designing a learning problem, it will be up to\\nyou to decide what features to choose, so if you are out in Portland gathering\\nhousing data, you might also decide to include other features such as whether\\neach house has a ﬁreplace, the number of bathrooms, and so on. We’ll say\\nmore about feature selection later, but for now let’s take the features as\\ngiven.)\\nTo perform supervised learning, we must decide how we’re going to rep-\\nresent functions/hypotheses hin a computer. As an initial choice, let’s say\\nwe decide to approximate yas a linear function of x:\\nhθ(x) =θ0+θ1x1+θ2x2\\nHere, theθi’s are the parameters (also called weights ) parameterizing the\\nspace of linear functions mapping from XtoY. When there is no risk of\\n8', metadata={'source': 'https://cs229.stanford.edu/lectures-spring2022/main_notes.pdf', 'page': 8}),\n",
       " Document(page_content='1.4 Locally weighted linear regression (optional\\nreading)\\nConsider the problem of predicting yfromx∈R. The leftmost ﬁgure below\\nshows the result of ﬁtting a y=θ0+θ1xto a dataset. We see that the data\\ndoesn’t really lie on straight line, and so the ﬁt is not very good.', metadata={'source': 'https://cs229.stanford.edu/lectures-spring2022/main_notes.pdf', 'page': 17}),\n",
       " Document(page_content='Chapter 2\\nClassiﬁcation and logistic\\nregression\\nLet’s now talk about the classiﬁcation problem. This is just like the regression\\nproblem, except that the values ywe now want to predict take on only\\na small number of discrete values. For now, we will focus on the binary\\nclassiﬁcation problem in which ycan take on only two values, 0 and 1.\\n(Most of what we say here will also generalize to the multiple-class case.)\\nFor instance, if we are trying to build a spam classiﬁer for email, then x(i)\\nmay be some features of a piece of email, and ymay be 1 if it is a piece\\nof spam mail, and 0 otherwise. 0 is also called the negative class , and 1\\nthepositive class , and they are sometimes also denoted by the symbols “-”\\nand “+.” Given x(i), the corresponding y(i)is also called the label for the\\ntraining example.\\n2.1 Logistic regression\\nWe could approach the classiﬁcation problem ignoring the fact that yis\\ndiscrete-valued, and use our old linear regression algorithm to try to predict\\nygivenx. However, it is easy to construct examples where this method\\nperforms very poorly. Intuitively, it also doesn’t make sense for hθ(x) to take\\nvalues larger than 1 or smaller than 0 when we know that y∈{0,1}.\\nTo ﬁx this, let’s change the form for our hypotheses hθ(x). We will choose\\nhθ(x) =g(θTx) =1\\n1 +e−θTx,\\nwhere\\ng(z) =1\\n1 +e−z\\n20', metadata={'source': 'https://cs229.stanford.edu/lectures-spring2022/main_notes.pdf', 'page': 20})]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b01f0e37-b18e-41de-962b-64b3edae5351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Contents\\nI Supervised learning 5\\n1 Linear regression 8\\n1.1 LMS algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . 9\\n1.2 The normal equations . . . . . . . . . . . . . . . . . . . . . . . 13\\n1.2.1 Matrix derivatives . . . . . . . . . . . . . . . . . . . . . 13\\n1.2.2 Least squares revisited . . . . . . . . . . . . . . . . . . 14\\n1.3 Probabilistic interpretation . . . . . . . . . . . . . . . . . . . . 15\\n1.4 Locally weighted linear regression (optional reading) . . . . . . 17\\n2 Classiﬁcation and logistic regression 20\\n2.1 Logistic regression . . . . . . . . . . . . . . . . . . . . . . . . 20\\n2.2 Digression: the perceptron learning algorithn . . . . . . . . . . 23\\n2.3 Another algorithm for maximizing ℓ(θ) . . . . . . . . . . . . . 24\\n3 Generalized linear models 26\\n3.1 The exponential family . . . . . . . . . . . . . . . . . . . . . . 26\\n3.2 Constructing GLMs . . . . . . . . . . . . . . . . . . . . . . . . 28\\n3.2.1 Ordinary least squares . . . . . . . . . . . . . . . . . . 29\\n3.2.2 Logistic regression . . . . . . . . . . . . . . . . . . . . 30\\n3.2.3 Softmax regression . . . . . . . . . . . . . . . . . . . . 30\\n4 Generative learning algorithms 35\\n4.1 Gaussian discriminant analysis . . . . . . . . . . . . . . . . . . 36\\n4.1.1 The multivariate normal distribution . . . . . . . . . . 36\\n4.1.2 The Gaussian discriminant analysis model . . . . . . . 39\\n4.1.3 Discussion: GDA and logistic regression . . . . . . . . 41', metadata={'source': 'https://cs229.stanford.edu/lectures-spring2022/main_notes.pdf', 'page': 1}),\n",
       " Document(page_content='Chapter 2\\nClassiﬁcation and logistic\\nregression\\nLet’s now talk about the classiﬁcation problem. This is just like the regression\\nproblem, except that the values ywe now want to predict take on only\\na small number of discrete values. For now, we will focus on the binary\\nclassiﬁcation problem in which ycan take on only two values, 0 and 1.\\n(Most of what we say here will also generalize to the multiple-class case.)\\nFor instance, if we are trying to build a spam classiﬁer for email, then x(i)\\nmay be some features of a piece of email, and ymay be 1 if it is a piece\\nof spam mail, and 0 otherwise. 0 is also called the negative class , and 1\\nthepositive class , and they are sometimes also denoted by the symbols “-”\\nand “+.” Given x(i), the corresponding y(i)is also called the label for the\\ntraining example.\\n2.1 Logistic regression\\nWe could approach the classiﬁcation problem ignoring the fact that yis\\ndiscrete-valued, and use our old linear regression algorithm to try to predict\\nygivenx. However, it is easy to construct examples where this method\\nperforms very poorly. Intuitively, it also doesn’t make sense for hθ(x) to take\\nvalues larger than 1 or smaller than 0 when we know that y∈{0,1}.\\nTo ﬁx this, let’s change the form for our hypotheses hθ(x). We will choose\\nhθ(x) =g(θTx) =1\\n1 +e−θTx,\\nwhere\\ng(z) =1\\n1 +e−z\\n20', metadata={'source': 'https://cs229.stanford.edu/lectures-spring2022/main_notes.pdf', 'page': 20}),\n",
       " Document(page_content='189\\nFor each action a∈A{\\nSamples′\\n1,...,s′\\nk∼Ps(i)a(using a model of the MDP).\\nSetq(a) =1\\nk∑k\\nj=1R(s(i)) +γV(s′\\nj)\\n//Hence,q(a) is an estimate of R(s(i)) +\\nγEs′∼Ps(i)a[V(s′)].\\n}\\nSety(i)= maxaq(a).\\n//Hence,y(i)is an estimate of R(s(i)) +\\nγmaxaEs′∼Ps(i)a[V(s′)].\\n}\\n//In the original value iteration algorithm (over discrete states)\\n//we updated the value function according to V(s(i)) :=y(i).\\n//In this algorithm, we want V(s(i))≈y(i), which we’ll achieve\\n//using supervised learning (linear regression).\\nSetθ:= arg min θ1\\n2∑n\\ni=1(\\nθTφ(s(i))−y(i))2\\n}\\nAbove, we had written out ﬁtted value iteration using linear regression\\nas the algorithm to try to make V(s(i)) close toy(i). That step of the algo-\\nrithm is completely analogous to a standard supervised learning (regression)\\nproblem in which we have a training set ( x(1),y(1)),(x(2),y(2)),..., (x(n),y(n)),\\nand want to learn a function mapping from xtoy; the only diﬀerence is that\\nheresplays the role of x. Even though our description above used linear re-\\ngression, clearly other regression algorithms (such as locally weighted linear\\nregression) can also be used.\\nUnlike value iteration over a discrete set of states, ﬁtted value iteration\\ncannot be proved to always to converge. However, in practice, it often does\\nconverge (or approximately converge), and works well for many problems.\\nNote also that if we are using a deterministic simulator/model of the MDP,\\nthen ﬁtted value iteration can be simpliﬁed by setting k= 1 in the algorithm.', metadata={'source': 'https://cs229.stanford.edu/lectures-spring2022/main_notes.pdf', 'page': 189}),\n",
       " Document(page_content='41\\n4.1.3 Discussion: GDA and logistic regression\\nThe GDA model has an interesting relationship to logistic regression. If we\\nview the quantity p(y= 1|x;φ,µ 0,µ1,Σ) as a function of x, we’ll ﬁnd that it\\ncan be expressed in the form\\np(y= 1|x;φ,Σ,µ0,µ1) =1\\n1 + exp(−θTx),\\nwhereθis some appropriate function of φ,Σ,µ0,µ1.1This is exactly the form\\nthat logistic regression—a discriminative algorithm—used to model p(y=\\n1|x).\\nWhen would we prefer one model over another? GDA and logistic regres-\\nsion will, in general, give diﬀerent decision boundaries when trained on the\\nsame dataset. Which is better?\\nWe just argued that if p(x|y) is multivariate gaussian (with shared Σ),\\nthenp(y|x) necessarily follows a logistic function. The converse, however,\\nis not true; i.e., p(y|x) being a logistic function does not imply p(x|y) is\\nmultivariate gaussian. This shows that GDA makes stronger modeling as-\\nsumptions about the data than does logistic regression. It turns out that\\nwhen these modeling assumptions are correct, then GDA will ﬁnd better ﬁts\\nto the data, and is a better model. Speciﬁcally, when p(x|y) is indeed gaus-\\nsian (with shared Σ), then GDA is asymptotically eﬃcient . Informally,\\nthis means that in the limit of very large training sets (large n), there is no\\nalgorithm that is strictly better than GDA (in terms of, say, how accurately\\nthey estimate p(y|x)). In particular, it can be shown that in this setting,\\nGDA will be a better algorithm than logistic regression; and more generally,', metadata={'source': 'https://cs229.stanford.edu/lectures-spring2022/main_notes.pdf', 'page': 41})]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb7f142-f850-475b-8bcc-74a978600546",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
